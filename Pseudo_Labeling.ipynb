{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pseudo Labeling.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "E3XularK0eWR",
        "t58UKjGK2vgI",
        "rouXBmj10uax",
        "OAk9FGyX2BlA",
        "yRifrZt12Jwg",
        "XzYR3ZUz2aaR"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nixXx13/jupyter-notebooks/blob/master/Pseudo_Labeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2cADtz1wiTy",
        "colab_type": "text"
      },
      "source": [
        "## Brief"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zv_7Q_1wqAr",
        "colab_type": "text"
      },
      "source": [
        "Ive tried tackling the task of image classification of 120 dog breeds.\n",
        "data included 10k labeled imgs and 10k test images without any label.\n",
        "\n",
        ".\n",
        "\n",
        "\n",
        "**The problem** - labeled training data isnt sufficient for achieving adequate model accuracy.\n",
        "\n",
        "**possible solution** - Because test data is very large, using [pseudo labeling](http://deeplearning.net/wp-content/uploads/2013/03/pseudo_label_final.pdf) might help increase accuracy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**The problem 2** - keras's flow_from_directory uses the img directory as its label while we want to use our pseudo generated labels.\n",
        "\n",
        "**possible solution 2** - implement our own generator so we can 'inject' our pseudo labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3XularK0eWR",
        "colab_type": "text"
      },
      "source": [
        "## Setup\n",
        "imports, data download and general functions declarations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzmGr9sn0dFK",
        "colab_type": "code",
        "outputId": "f440a391-483d-4714-bd87-77674ba44b40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "%pylab inline\n",
        "import numpy as np\n",
        "\n",
        "# importing utils from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "UTILS_DRIVE_FNAMES = ['thirdPartyUtils.py' , 'py_utils.py']\n",
        "UTILS_DRIVE_DIR = '/content/drive/My Drive/Colab Notebooks/Utils/'\n",
        "for fname in UTILS_DRIVE_FNAMES:\n",
        "  with open('{}{}'.format(UTILS_DRIVE_DIR,fname), 'r') as f:\n",
        "    with open(fname,'w') as fw:\n",
        "      fw.write(f.read())\n",
        "    \n",
        "from thirdPartyUtils import colab_utils\n",
        "colab_utils(setupKaggle = True)\n",
        "\n",
        "!pip install bcolz\n",
        "from py_utils import *\n",
        "# Pics inflation and dir oredering\n",
        "\n",
        "!kaggle competitions download -c dog-breed-identification\n",
        "HOME = '/content/dogBreed'\n",
        "\n",
        "!unzip labels.csv.zip\n",
        "import csv\n",
        "\n",
        "mydict = csvToDict(\"labels.csv\")\n",
        "del mydict['id']\n",
        "\n",
        "classes = list(set(mydict.values()))\n",
        "makeDirs(classes,'/content/dogBreed')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Download 100%.\n",
            " === Kaggle setup succeeded!\n",
            "Collecting bcolz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/4e/23942de9d5c0fb16f10335fa83e52b431bcb8c0d4a8419c9ac206268c279/bcolz-1.2.1.tar.gz (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from bcolz) (1.16.5)\n",
            "Building wheels for collected packages: bcolz\n",
            "  Building wheel for bcolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bcolz: filename=bcolz-1.2.1-cp36-cp36m-linux_x86_64.whl size=2661601 sha256=337187b65573e328efeb7e83b5725171a4edd5de4029c38dce64e5e4707e46a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/78/26/fb8c0acb91a100dc8914bf236c4eaa4b207cb876893c40b745\n",
            "Successfully built bcolz\n",
            "Installing collected packages: bcolz\n",
            "Successfully installed bcolz-1.2.1\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading labels.csv.zip to /content\n",
            "  0% 0.00/214k [00:00<?, ?B/s]\n",
            "100% 214k/214k [00:00<00:00, 65.4MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/281k [00:00<?, ?B/s]\n",
            "100% 281k/281k [00:00<00:00, 85.7MB/s]\n",
            "Downloading test.zip to /content\n",
            " 96% 332M/346M [00:03<00:00, 110MB/s]\n",
            "100% 346M/346M [00:03<00:00, 103MB/s]\n",
            "Downloading train.zip to /content\n",
            " 99% 340M/345M [00:02<00:00, 147MB/s]\n",
            "100% 345M/345M [00:02<00:00, 131MB/s]\n",
            "Archive:  labels.csv.zip\n",
            "  inflating: labels.csv              \n",
            " === Created 120 dirs in /content/dogBreed/<train/valid> dir succesfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0tifdnWUsYO",
        "colab_type": "code",
        "outputId": "1a4ab872-19a5-499d-e50d-a5905dafd486",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!unzip train.zip -d /content/dogBreed | wc -l\n",
        "import shutil\n",
        "\n",
        "trainDir = '/content/dogBreed/train'\n",
        "\n",
        "!ls -l $trainDir/*.jpg | wc -l\n",
        "i=0\n",
        "for k in mydict.keys():\n",
        "  shutil.move('{}/{}.jpg'.format(trainDir,k) , '{}/{}/{}.jpg'.format(trainDir,mydict[k],k))\n",
        "  i+=1\n",
        "  \n",
        "print(' === moved {} files succesfully to train dir'.format(i))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10223\n",
            "10222\n",
            " === moved 10222 files succesfully to train dir\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voUMa4oZlJ9Y",
        "colab_type": "code",
        "outputId": "8c82b05e-37cc-4db0-971e-d4bcdd72f797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from glob import glob\n",
        "g = glob(HOME+\"/train/*/*.jpg\")\n",
        "g_rand = np.random.permutation(g)\n",
        "\n",
        "# VALID_NUM = 4000\n",
        "VALID_NUM = 2000\n",
        "\n",
        "i=0\n",
        "for i in range(VALID_NUM):\n",
        "  shutil.move(g_rand[i] , g_rand[i].replace('train','valid') )\n",
        "  i+=1\n",
        "\n",
        "print(' === moved {} files succesfully to valid dir'.format(i))\n",
        "\n",
        "g_train = glob(HOME+'/train/*/*.jpg')\n",
        "g_valid = glob(HOME+'/valid/*/*.jpg')\n",
        "\n",
        "print(' === {} pics in train dirs'.format(len(g_train)))\n",
        "print(' === {} pics in valid dirs'.format(len(g_valid)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " === moved 2000 files succesfully to valid dir\n",
            " === 8222 pics in train dirs\n",
            " === 2000 pics in valid dirs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8J1WoZJbnpom",
        "colab_type": "code",
        "outputId": "0e89fdf0-48c7-498b-8345-ab75c22d6f0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#unpacking test.zip to proper dir\n",
        "\n",
        "testDir = \"/content/dogBreed/test/unknown\"\n",
        "g_testDir = glob(testDir + \"/*.jpg\")\n",
        "\n",
        "if len(g_testDir) == 0:\n",
        "  !unzip test.zip -d /content/dogBreed/test | wc -l\n",
        "\n",
        "  from glob import glob\n",
        "  g = glob(\"/content/dogBreed/test/test/*.jpg\")\n",
        "\n",
        "  len(g)\n",
        "\n",
        "  for img in g:\n",
        "  #   print(img.replace(\"test/test\",\"test/unknown\"))\n",
        "    shutil.move(img ,img.replace(\"test/test\",\"test/unknown\") )\n",
        "\n",
        "  !ls -l /content/dogBreed/test/unknown | wc -l\n",
        "\n",
        "  !rm -rf /content/dogBreed/test/test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10359\n",
            "10358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgMIzKp7nNYQ",
        "colab_type": "code",
        "outputId": "4c3f19f5-757f-42c7-f9a3-389f62de8811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "# layers\n",
        "from keras.layers import Flatten,Dense,Conv2D,MaxPooling2D,Dropout,BatchNormalization,Convolution2D\n",
        "\n",
        "# optimizers\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.layers.core import Lambda\n",
        "\n",
        "def getVggTop():\n",
        "  \n",
        "  vgg = keras.applications.VGG16(weights = \"imagenet\", include_top=False,input_shape=(224,224,3))\n",
        "  model = Sequential()\n",
        "  model.add(Lambda(preprocess_input, input_shape=(224,224,3), output_shape=(224,224,3)))\n",
        "\n",
        "  vgg_layers = vgg.layers\n",
        "  vgg_layers.pop(0)\n",
        "  for layer in vgg_layers:\n",
        "    layer.trainable=False\n",
        "    model.add(layer)\n",
        "    \n",
        "  return model\n",
        "\n",
        "def getModel(\n",
        "    do_cnn = 0.2,\n",
        "    do_dense = 0.5,\n",
        "    dense_width = 256,\n",
        "    verbose = 0\n",
        "  ):\n",
        "  model = Sequential(\n",
        "        getVggTop().layers + \n",
        "        [\n",
        "         MaxPooling2D(),\n",
        "         BatchNormalization(),\n",
        "         Dropout(0.2),\n",
        "         Flatten(),\n",
        "         Dense(256,activation='relu'),\n",
        "         BatchNormalization(),\n",
        "         Dropout(0.4),\n",
        "         Dense(120,activation='softmax')\n",
        "        ]\n",
        "   )\n",
        "  print(model)\n",
        "  print(model.summary()) if verbose else None\n",
        "  return model\n",
        "\n",
        "from keras.preprocessing import image\n",
        "BS=64\n",
        "\n",
        "def get_batch(\n",
        "    dir,\n",
        "    gen          = image.ImageDataGenerator(), \n",
        "    batch_size   = 64,\n",
        "    shuffle      = True,\n",
        "    target_size  = (224,224),\n",
        "    class_mode   = 'categorical'\n",
        "    ):\n",
        "    return gen.flow_from_directory(dir,class_mode = class_mode,target_size=target_size,shuffle = shuffle,batch_size = batch_size )\n",
        "\n",
        "def get_batches(fDir,\n",
        "                gen = image.ImageDataGenerator(), \n",
        "                shuffle = False,\n",
        "                batch_size = 64,\n",
        "                class_mode = 'categorical',\n",
        "                target_size= (224,224),\n",
        "               ):\n",
        "    str_shuffle = \"train_shuffle\".ljust(20,\" \")\n",
        "    str_batch_size = \"batch_size\".ljust(20,\" \")\n",
        "    str_class_mode = \"class_mode\".ljust(20,\" \")\n",
        "    gen_id         = \"gen used\".ljust(20,\" \")\n",
        "    str_target_size = \"target_size\".ljust(20,\" \")\n",
        "    print(\"Creating batches with following params -\\n{}:{}\\n{}:{}\\n{}:{}\\n{}:{}\\n{}:{}\\n\".format(str_shuffle,shuffle,str_batch_size,batch_size,str_class_mode,class_mode,gen_id,str(gen),str_target_size,str(target_size)))\n",
        "    train_batch = get_batch(fDir + '/train',gen = gen,batch_size=batch_size,shuffle=shuffle,class_mode=class_mode,target_size=target_size)\n",
        "    valid_batch = get_batch(fDir + '/valid',gen = gen,batch_size=batch_size,shuffle=False,class_mode=class_mode,target_size=target_size)\n",
        "    test_batch  = get_batch(fDir + '/test',gen = gen,batch_size=batch_size,shuffle=False,class_mode=class_mode,target_size=target_size)\n",
        "    \n",
        "    return train_batch,valid_batch,test_batch\n",
        "\n",
        "from keras.utils.np_utils import to_categorical    \n",
        "        \n",
        "def pyPlot(histList,pType=['acc','loss'],titleList = None):\n",
        "  \n",
        "    def getMaxValue(historyObj,plotType,prevMax):\n",
        "      maxVal = max([max(historyObj.history['{}'.format(plotType)]) , max(historyObj.history['val_{}'.format(plotType)])])\n",
        "      if prevMax>maxVal:\n",
        "        return prevMax\n",
        "      return maxVal\n",
        "  \n",
        "    def setDefaultTitles():\n",
        "      titleList = []\n",
        "      for i in range(len(histList)):\n",
        "        titleList.append(str(i))\n",
        "      return titleList\n",
        "          \n",
        "    if type(histList) != list:\n",
        "      tmp = histList\n",
        "      histList = []\n",
        "      histList.append(tmp)\n",
        "      \n",
        "    if titleList != None:\n",
        "      if len(titleList) != len(histList):\n",
        "        print(\"Titles number !=  Hists number, Setting default titles\")\n",
        "        titleList = setDefaultTitles()\n",
        "    \n",
        "    else:\n",
        "      titleList = setDefaultTitles()\n",
        "          \n",
        "    ncols = len(pType)\n",
        "    plt.figure(figsize=(15,15))\n",
        "    \n",
        "    for i,pt in enumerate(pType):\n",
        "      \n",
        "      plt.subplot(2,ncols,i+1)\n",
        "      plt.title(pt)\n",
        "      plt.ylabel('{}'.format(pt))\n",
        "      plt.xlabel('epoch')\n",
        "      \n",
        "      legend = []\n",
        "      maxVal = 1\n",
        "\n",
        "      for j,h in enumerate(histList):\n",
        "        plt.plot(h.history['{}'.format(pt)])\n",
        "        plt.plot(h.history['val_{}'.format(pt)])\n",
        "\n",
        "        legend.append('train \"{}\"'.format(titleList[j]))\n",
        "        legend.append('valid \"{}\"'.format(titleList[j]))\n",
        "        \n",
        "        maxVal = getMaxValue(h,pt,maxVal)\n",
        "\n",
        "      plt.ylim(0,maxVal+0.2)\n",
        "      plt.legend(legend,loc=0)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t58UKjGK2vgI",
        "colab_type": "text"
      },
      "source": [
        "## Generator implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2FELf9r5c1p",
        "colab_type": "text"
      },
      "source": [
        "In order to benefit from pseudo labeling, Pseudo labeled data vs regualar training labeled data should be in a certain ratio.\n",
        "\n",
        "***mixIterator*** takes two iterators and wraps them as one iterator.\n",
        "Ive used it to mix regualar training iterator with 48 batch size and pseudo labeled iterator of 16 batch size to achieve a 64 mixed iterator with a ratio of 25% pseudo labeled data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJxwmkpA5aNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class mixIterator():\n",
        "  def __init__(self,itersList):\n",
        "    self.itersList = itersList\n",
        "    self.samples = sum([it.samples for it in itersList])\n",
        "    print(\"mixIterator:Total number of imgs {}\".format(self.samples))\n",
        "   \n",
        "  def reset(self):\n",
        "    for it in self.itersList : it.reset \n",
        "  \n",
        "  def __iter__(self):\n",
        "    return self\n",
        "  \n",
        "  def __next__(self):\n",
        "    a = next(self.itersList[0])\n",
        "    b = next(self.itersList[1])\n",
        "    imgs = np.concatenate((a[0],b[0]))\n",
        "    labels = np.concatenate((a[1],b[1])) \n",
        "\n",
        "    return (imgs,labels)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYrr4ZU463zw",
        "colab_type": "text"
      },
      "source": [
        "***exteralLabelsIter*** (External Labels Iter).accepts external labels as argument to its constructor.\n",
        "uses keras's flow_from_directory (with class_mode = None which returns solely imgs without any labels) and returns a label assosiated with it from the labels argument. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYWU5Nn223KJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class exteralLabelsIter():\n",
        "  def __init__(self,directory,labels,\n",
        "                      batch_size,\n",
        "                      target_size = (224,224),\n",
        "                      gen = image.ImageDataGenerator(), \n",
        "              ):\n",
        "    self.imgIter = get_batch(directory,batch_size=int(batch_size),shuffle=False,class_mode=None,target_size=target_size,gen=gen)\n",
        "    self.labels = np.concatenate([labels,labels]) # make room for extras\n",
        "    self.labels_realSize = int(self.labels.shape[0]/2)\n",
        "    self.BS = int(batch_size)\n",
        "    self.firstIndex = 0\n",
        "    if self.labels_realSize != self.imgIter.samples:\n",
        "      raise Exception(\"exteralLabelsIter:Mismatch! Imgs number is {} and labels num is {}\".format(self.imgIter.samples,self.labels_realSize))\n",
        "    self.samples = self.imgIter.samples\n",
        "  \n",
        "  def reset(self):\n",
        "    self.imgIter.reset()\n",
        "    self.firstIndex = 0\n",
        "  \n",
        "  def __iter__(self):\n",
        "    return self\n",
        "  \n",
        "  def __next__(self):\n",
        "    imgs = next(self.imgIter)\n",
        "    \n",
        "    labels_num = imgs.shape[0] # equals self.Bs or less when reacing end of imgs list\n",
        "    \n",
        "    endIndex = self.firstIndex+labels_num\n",
        "    if self.firstIndex>=self.labels_realSize and endIndex>=self.labels_realSize:\n",
        "      self.firstIndex=int(self.firstIndex%self.labels_realSize)\n",
        "      \n",
        "    endIndex = self.firstIndex+labels_num\n",
        "    \n",
        "    labels = self.labels[self.firstIndex:endIndex]\n",
        "    self.firstIndex = endIndex\n",
        "    \n",
        "    return (imgs,labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rouXBmj10uax",
        "colab_type": "text"
      },
      "source": [
        "## Base model training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cztCS07s3YKN",
        "colab_type": "text"
      },
      "source": [
        "We will use base model weights as our starting point to the following training processes (which will run 10 addional epochs each):\n",
        "\n",
        "\n",
        "*   Training a model using labeled data only.\n",
        " \n",
        "*   Training a model using data with pseudo labeling ( as one hot vectors ) as described in the paper ( link in brief ).\n",
        "* Training a model using data with pseudo labeling ( as probability vectors ).\n",
        "\n",
        "\n",
        "training set has 8222 imgs, validation set is 2000.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueTapEqK2Aei",
        "colab_type": "code",
        "outputId": "107bd54a-df55-4a3b-bf18-d597b4059e94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "lr = 3e-3\n",
        "EP = 10\n",
        "hists = []\n",
        "BS = 64\n",
        "gen = image.ImageDataGenerator(rotation_range=10, width_shift_range=0.1, \n",
        "       height_shift_range=0.1, shear_range=0.15, zoom_range=0.1, \n",
        "       channel_shift_range=10., horizontal_flip=True)\n",
        "\n",
        "titles = [ \"\" ]\n",
        "\n",
        "\n",
        "train_batch,valid_batch,test_batch = get_batches(HOME, shuffle=True, batch_size=BS,gen=gen)\n",
        "\n",
        "train_classes = train_batch.classes\n",
        "train_labels = to_categorical(train_batch.classes)\n",
        "train_filenames = train_batch.filenames\n",
        "\n",
        "val_classes = valid_batch.classes\n",
        "val_labels = to_categorical(valid_batch.classes)\n",
        "val_filenames = valid_batch.filenames\n",
        "\n",
        "model = getModel()\n",
        "model.compile(Adam(lr=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "hist = model.fit_generator(train_batch,\n",
        "                            steps_per_epoch = train_batch.samples/BS,\n",
        "                            validation_data = valid_batch,\n",
        "                            validation_steps = valid_batch.samples/BS,\n",
        "                            epochs=EP)\n",
        "\n",
        "hists.append(hist)\n",
        "\n",
        "pyPlot(hists,titleList=titles)\n",
        "\n",
        "model.save_weights(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating batches with following params -\n",
            "train_shuffle       :True\n",
            "batch_size          :64\n",
            "class_mode          :categorical\n",
            "gen used            :<keras.preprocessing.image.ImageDataGenerator object at 0x7f94fb96f358>\n",
            "target_size         :(224, 224)\n",
            "\n",
            "Found 8222 images belonging to 120 classes.\n",
            "Found 2000 images belonging to 120 classes.\n",
            "Found 10357 images belonging to 1 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "<keras.engine.sequential.Sequential object at 0x7f94c03066a0>\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/10\n",
            "129/128 [==============================] - 182s 1s/step - loss: 3.0071 - acc: 0.2974 - val_loss: 1.7263 - val_acc: 0.5120\n",
            "Epoch 2/10\n",
            "129/128 [==============================] - 164s 1s/step - loss: 1.4977 - acc: 0.5824 - val_loss: 1.4689 - val_acc: 0.5765\n",
            "Epoch 3/10\n",
            "129/128 [==============================] - 166s 1s/step - loss: 1.2154 - acc: 0.6449 - val_loss: 1.4170 - val_acc: 0.6000\n",
            "Epoch 4/10\n",
            "129/128 [==============================] - 165s 1s/step - loss: 1.0008 - acc: 0.7039 - val_loss: 1.3593 - val_acc: 0.6185\n",
            "Epoch 5/10\n",
            "129/128 [==============================] - 164s 1s/step - loss: 0.9092 - acc: 0.7296 - val_loss: 1.4035 - val_acc: 0.6095\n",
            "Epoch 6/10\n",
            "129/128 [==============================] - 164s 1s/step - loss: 0.8369 - acc: 0.7453 - val_loss: 1.4219 - val_acc: 0.6165\n",
            "Epoch 7/10\n",
            "129/128 [==============================] - 167s 1s/step - loss: 0.7817 - acc: 0.7528 - val_loss: 1.4287 - val_acc: 0.6035\n",
            "Epoch 8/10\n",
            "129/128 [==============================] - 167s 1s/step - loss: 0.7129 - acc: 0.7769 - val_loss: 1.4862 - val_acc: 0.5930\n",
            "Epoch 9/10\n",
            "129/128 [==============================] - 165s 1s/step - loss: 0.6669 - acc: 0.7936 - val_loss: 1.4752 - val_acc: 0.6005\n",
            "Epoch 10/10\n",
            "129/128 [==============================] - 167s 1s/step - loss: 0.6376 - acc: 0.8006 - val_loss: 1.4748 - val_acc: 0.6045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3sAAAGwCAYAAAAQfXy9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8CHKHgAAAAD4EGUPAAAAAHzo/wO9+71MZX7CCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4JVnNuUibjV",
        "colab_type": "text"
      },
      "source": [
        "Validation set reached plateau ( not 100% because it keeps on decending but in a slow rate ) of loss around ~1.4 and accuracy around ~0.6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAk9FGyX2BlA",
        "colab_type": "text"
      },
      "source": [
        "## Training data with labeled data only\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl4m3Vo62IwZ",
        "colab_type": "code",
        "outputId": "4d69f446-d753-4685-fd2b-3e5c8fd6f5f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "model.load_weights(\"model.h5\")\n",
        "EP = 10\n",
        "hist = model.fit_generator(train_batch,\n",
        "                            steps_per_epoch = train_batch.samples/BS,\n",
        "                            validation_data = valid_batch,\n",
        "                            validation_steps = valid_batch.samples/BS,\n",
        "                            epochs=EP)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "129/128 [==============================] - 178s 1s/step - loss: 0.6155 - acc: 0.8014 - val_loss: 1.4368 - val_acc: 0.6100\n",
            "Epoch 2/10\n",
            "129/128 [==============================] - 167s 1s/step - loss: 0.5517 - acc: 0.8216 - val_loss: 1.4993 - val_acc: 0.6125\n",
            "Epoch 3/10\n",
            "129/128 [==============================] - 166s 1s/step - loss: 0.5781 - acc: 0.8181 - val_loss: 1.5060 - val_acc: 0.6210\n",
            "Epoch 4/10\n",
            "129/128 [==============================] - 165s 1s/step - loss: 0.5575 - acc: 0.8280 - val_loss: 1.4871 - val_acc: 0.6270\n",
            "Epoch 5/10\n",
            "129/128 [==============================] - 165s 1s/step - loss: 0.5228 - acc: 0.8341 - val_loss: 1.4923 - val_acc: 0.6250\n",
            "Epoch 6/10\n",
            "129/128 [==============================] - 166s 1s/step - loss: 0.5009 - acc: 0.8407 - val_loss: 1.5460 - val_acc: 0.6105\n",
            "Epoch 7/10\n",
            "129/128 [==============================] - 166s 1s/step - loss: 0.4652 - acc: 0.8497 - val_loss: 1.5194 - val_acc: 0.6230\n",
            "Epoch 8/10\n",
            "129/128 [==============================] - 166s 1s/step - loss: 0.4865 - acc: 0.8415 - val_loss: 1.5719 - val_acc: 0.6135\n",
            "Epoch 9/10\n",
            "129/128 [==============================] - 165s 1s/step - loss: 0.4624 - acc: 0.8470 - val_loss: 1.5327 - val_acc: 0.6215\n",
            "Epoch 10/10\n",
            "129/128 [==============================] - 165s 1s/step - loss: 0.4364 - acc: 0.8605 - val_loss: 1.5279 - val_acc: 0.6270\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRifrZt12Jwg",
        "colab_type": "text"
      },
      "source": [
        "## Training data with pseudo labeling - as one hot vectors.\n",
        "in addition to training set of 8222 imgs, a test set with pseudo labels of 10357 imgs is added to the training process.\n",
        "\n",
        "ratio of training/pseudo imgs in a batch of 64 imgs is 75%/25%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PbgzAWb2dvB",
        "colab_type": "code",
        "outputId": "e715e3c5-392b-4a91-8548-1f0700ddaacf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.load_weights(\"model.h5\")\n",
        "\n",
        "BS = 64\n",
        "_train_batch,_,_ = get_batches(HOME, shuffle=True, batch_size=int(3*(BS/4)),gen=gen)\n",
        "_,_valid_batch,_test_batch = get_batches(HOME, batch_size=int(BS/4),gen=gen)\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "  pseudo_test_labels = model.predict_generator(_test_batch,_test_batch.samples/int(BS/4),verbose=1) \n",
        "  \n",
        "  pseudo_test_labels_binary = np.zeros(pseudo_test_labels.shape)\n",
        "  idxs = np.argmax(pseudo_test_labels,axis=1)\n",
        "\n",
        "  numLabels = pseudo_test_labels.shape[0]\n",
        "  pseudo_test_labels_binary[np.arange(numLabels),idxs]=1\n",
        "\n",
        "  pseudo_test_batch = exteralLabelsIter(HOME + '/test',pseudo_test_labels_binary, batch_size=BS/4,gen=gen)\n",
        "  mixedIter = mixIterator([_train_batch,pseudo_test_batch])\n",
        "\n",
        "  EP = 1\n",
        "  model.fit_generator(mixedIter,\n",
        "                            steps_per_epoch = mixedIter.samples/BS,\n",
        "                            validation_data = valid_batch,\n",
        "                            validation_steps = valid_batch.samples/BS,\n",
        "                            epochs=EP)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating batches with following params -\n",
            "train_shuffle       :True\n",
            "batch_size          :48\n",
            "class_mode          :categorical\n",
            "gen used            :<keras.preprocessing.image.ImageDataGenerator object at 0x7f94fb96f358>\n",
            "target_size         :(224, 224)\n",
            "\n",
            "Found 8222 images belonging to 120 classes.\n",
            "Found 2000 images belonging to 120 classes.\n",
            "Found 10357 images belonging to 1 classes.\n",
            "Creating batches with following params -\n",
            "train_shuffle       :False\n",
            "batch_size          :16\n",
            "class_mode          :categorical\n",
            "gen used            :<keras.preprocessing.image.ImageDataGenerator object at 0x7f94fb96f358>\n",
            "target_size         :(224, 224)\n",
            "\n",
            "Found 8222 images belonging to 120 classes.\n",
            "Found 2000 images belonging to 120 classes.\n",
            "Found 10357 images belonging to 1 classes.\n",
            "648/647 [==============================] - 180s 277ms/step\n",
            "Found 10357 images belonging to 1 classes.\n",
            "mixIterator:Total number of imgs 18579\n",
            "Epoch 1/1\n",
            "291/290 [==============================] - 355s 1s/step - loss: 1.0907 - acc: 0.6824 - val_loss: 1.5139 - val_acc: 0.5910\n",
            "648/647 [==============================] - 181s 279ms/step\n",
            "Found 10357 images belonging to 1 classes.\n",
            "mixIterator:Total number of imgs 18579\n",
            "Epoch 1/1\n",
            "291/290 [==============================] - 355s 1s/step - loss: 0.9508 - acc: 0.7198 - val_loss: 1.4334 - val_acc: 0.6175\n",
            "648/647 [==============================] - 183s 282ms/step\n",
            "Found 10357 images belonging to 1 classes.\n",
            "mixIterator:Total number of imgs 18579\n",
            "Epoch 1/1\n",
            "291/290 [==============================] - 360s 1s/step - loss: 0.8202 - acc: 0.7470 - val_loss: 1.3882 - val_acc: 0.6225\n",
            "648/647 [==============================] - 184s 284ms/step\n",
            "Found 10357 images belonging to 1 classes.\n",
            "mixIterator:Total number of imgs 18579\n",
            "Epoch 1/1\n",
            "291/290 [==============================] - 362s 1s/step - loss: 0.7533 - acc: 0.7708 - val_loss: 1.3301 - val_acc: 0.6495\n",
            "648/647 [==============================] - 184s 284ms/step\n",
            "Found 10357 images belonging to 1 classes.\n",
            "mixIterator:Total number of imgs 18579\n",
            "Epoch 1/1\n",
            "291/290 [==============================] - 359s 1s/step - loss: 0.6807 - acc: 0.7877 - val_loss: 1.3501 - val_acc: 0.6390\n",
            "648/647 [==============================] - 184s 284ms/step\n",
            "Found 10357 images belonging to 1 classes.\n",
            "mixIterator:Total number of imgs 18579\n",
            "Epoch 1/1\n",
            "291/290 [==============================] - 358s 1s/step - loss: 0.6643 - acc: 0.7976 - val_loss: 1.3973 - val_acc: 0.6380\n",
            "648/647 [==============================] - 183s 282ms/step\n",
            "Found 10357 images belonging to 1 classes.\n",
            "mixIterator:Total number of imgs 18579\n",
            "Epoch 1/1\n",
            "291/290 [==============================] - 357s 1s/step - loss: 0.6288 - acc: 0.8054 - val_loss: 1.3610 - val_acc: 0.6310\n",
            "648/647 [==============================] - 185s 285ms/step\n",
            "Found 10357 images belonging to 1 classes.\n",
            "mixIterator:Total number of imgs 18579\n",
            "Epoch 1/1\n",
            "291/290 [==============================] - 363s 1s/step - loss: 0.5894 - acc: 0.8146 - val_loss: 1.4305 - val_acc: 0.6440\n",
            "648/647 [==============================] - 185s 286ms/step\n",
            "Found 10357 images belonging to 1 classes.\n",
            "mixIterator:Total number of imgs 18579\n",
            "Epoch 1/1\n",
            "291/290 [==============================] - 364s 1s/step - loss: 0.5564 - acc: 0.8269 - val_loss: 1.3718 - val_acc: 0.6500\n",
            "648/647 [==============================] - 184s 283ms/step\n",
            "Found 10357 images belonging to 1 classes.\n",
            "mixIterator:Total number of imgs 18579\n",
            "Epoch 1/1\n",
            "291/290 [==============================] - 363s 1s/step - loss: 0.5526 - acc: 0.8284 - val_loss: 1.4057 - val_acc: 0.6355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzYR3ZUz2aaR",
        "colab_type": "text"
      },
      "source": [
        "## Training data with pseudo labeling - as probabily vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW_wKDHS2S8h",
        "colab_type": "code",
        "outputId": "99cd6df9-b583-4551-e625-2a19b359fb66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.load_weights(\"model.h5\")\n",
        "\n",
        "BS = 64\n",
        "_train_batch,_,_ = get_batches(HOME, shuffle=True, batch_size=int(3*(BS/4)),gen=gen)\n",
        "_,_valid_batch,_test_batch = get_batches(HOME, batch_size=int(BS/4),gen=gen)\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "  pseudo_test_labels = model.predict_generator(_test_batch,_test_batch.samples/int(BS/4),verbose=1) \n",
        "\n",
        "  pseudo_test_batch = exteralLabelsIter(HOME + '/test',pseudo_test_labels, batch_size=BS/4,gen=gen)\n",
        "  mixedIter = mixIterator([_train_batch,pseudo_test_batch])\n",
        "\n",
        "  EP = 1\n",
        "  model.fit_generator(mixedIter,\n",
        "                            steps_per_epoch = mixedIter.samples/BS,\n",
        "                            validation_data = valid_batch,\n",
        "                            validation_steps = valid_batch.samples/BS,\n",
        "                            epochs=EP)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating batches with following params -\n",
            "train_shuffle       :True\n",
            "batch_size          :48\n",
            "class_mode          :categorical\n",
            "gen used            :<keras.preprocessing.image.ImageDataGenerator object at 0x7f94fb96f358>\n",
            "target_size         :(224, 224)\n",
            "\n",
            "Found 8222 images belonging to 120 classes.\n",
            "Found 2000 images belonging to 120 classes.\n",
            "Found 10357 images belonging to 1 classes.\n",
            "Creating batches with following params -\n",
            "train_shuffle       :False\n",
            "batch_size          :16\n",
            "class_mode          :categorical\n",
            "gen used            :<keras.preprocessing.image.ImageDataGenerator object at 0x7f94fb96f358>\n",
            "target_size         :(224, 224)\n",
            "\n",
            "Found 8222 images belonging to 120 classes.\n",
            "Found 2000 images belonging to 120 classes.\n",
            "Found 10357 images belonging to 1 classes.\n",
            "648/647 [==============================] - 188s 290ms/step\n",
            "Found 10357 images belonging to 1 classes.\n",
            "mixIterator:Total number of imgs 18579\n",
            "Epoch 1/1\n",
            "291/290 [==============================] - 370s 1s/step - loss: 1.2055 - acc: 0.6794 - val_loss: 1.4334 - val_acc: 0.6105\n",
            "648/647 [==============================] - 189s 292ms/step\n",
            "Found 10357 images belonging to 1 classes.\n",
            "mixIterator:Total number of imgs 18579\n",
            "Epoch 1/1\n",
            "291/290 [==============================] - 370s 1s/step - loss: 1.0340 - acc: 0.7281 - val_loss: 1.3472 - val_acc: 0.6255\n",
            "648/647 [==============================] - 190s 294ms/step\n",
            "Found 10357 images belonging to 1 classes.\n",
            "mixIterator:Total number of imgs 18579\n",
            "Epoch 1/1\n",
            "291/290 [==============================] - 373s 1s/step - loss: 0.9114 - acc: 0.7604 - val_loss: 1.3568 - val_acc: 0.6160\n",
            "648/647 [==============================] - 189s 292ms/step\n",
            "Found 10357 images belonging to 1 classes.\n",
            "mixIterator:Total number of imgs 18579\n",
            "Epoch 1/1\n",
            "291/290 [==============================] - 370s 1s/step - loss: 0.8507 - acc: 0.7808 - val_loss: 1.3093 - val_acc: 0.6265\n",
            "648/647 [==============================] - 188s 290ms/step\n",
            "Found 10357 images belonging to 1 classes.\n",
            "mixIterator:Total number of imgs 18579\n",
            "Epoch 1/1\n",
            "291/290 [==============================] - 373s 1s/step - loss: 0.7936 - acc: 0.7994 - val_loss: 1.3020 - val_acc: 0.6315\n",
            "648/647 [==============================] - 189s 292ms/step\n",
            "Found 10357 images belonging to 1 classes.\n",
            "mixIterator:Total number of imgs 18579\n",
            "Epoch 1/1\n",
            "291/290 [==============================] - 372s 1s/step - loss: 0.7814 - acc: 0.7971 - val_loss: 1.2900 - val_acc: 0.6295\n",
            "648/647 [==============================] - 190s 293ms/step\n",
            "Found 10357 images belonging to 1 classes.\n",
            "mixIterator:Total number of imgs 18579\n",
            "Epoch 1/1\n",
            "291/290 [==============================] - 370s 1s/step - loss: 0.7561 - acc: 0.8096 - val_loss: 1.3027 - val_acc: 0.6350\n",
            "648/647 [==============================] - 190s 294ms/step\n",
            "Found 10357 images belonging to 1 classes.\n",
            "mixIterator:Total number of imgs 18579\n",
            "Epoch 1/1\n",
            "291/290 [==============================] - 371s 1s/step - loss: 0.7135 - acc: 0.8188 - val_loss: 1.2805 - val_acc: 0.6395\n",
            "648/647 [==============================] - 190s 293ms/step\n",
            "Found 10357 images belonging to 1 classes.\n",
            "mixIterator:Total number of imgs 18579\n",
            "Epoch 1/1\n",
            "291/290 [==============================] - 370s 1s/step - loss: 0.6909 - acc: 0.8238 - val_loss: 1.3207 - val_acc: 0.6385\n",
            "648/647 [==============================] - 188s 291ms/step\n",
            "Found 10357 images belonging to 1 classes.\n",
            "mixIterator:Total number of imgs 18579\n",
            "Epoch 1/1\n",
            "291/290 [==============================] - 370s 1s/step - loss: 0.6866 - acc: 0.8234 - val_loss: 1.3027 - val_acc: 0.6340\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6w4mz0_2eZW",
        "colab_type": "text"
      },
      "source": [
        "## Summary!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZhbl3xYu0C1",
        "colab_type": "text"
      },
      "source": [
        "*general note - \n",
        "I am putting aside the unsatisfactory accuracy of all models and mainly relate to conclusions regarding the psuedo labeling process.\n",
        "\n",
        "\n",
        "**Comparison**\n",
        "1. **regular trainging process**\n",
        "\n",
        "  - test set - loss was decreasing from 0.6 to 0.43, accuracy from 0.8 to 0.86.\n",
        "\n",
        "  - Validation set - loss incread to ~1.5 and best accuracy achieved is 0.627\n",
        "\n",
        "\n",
        "2. **pseudo labeling ( as one hot vectors ) training process**\n",
        "\n",
        "  - test set - loss jumped to ~1, as expected, and reached 0.55 at the end.\n",
        "\n",
        "  - Validation set - loss oscilates in range 1.33-14.3. best valition accuracy is 0.65 in 9th epoch.\n",
        "\n",
        "  - Note worth further checking - \n",
        "  \n",
        "    Might be interesting to see that 9th epoch test accuracy is 0.827.if we look at 'regular model training' epochs we can see that epoch with close training accuracy reached validation accuracy of 0.827.\n",
        "    \n",
        "    If current training process will continue to train more epochs, it might get better validation accuracy when reaching 'regular model training' best training accuracy (which is 0.86).\n",
        "\n",
        "3.  **pseudo labeling ( as probabily vectors ) training process**\n",
        "  - test set - comparing to previous pseudo labeling method, loss is higher in ~0.2 and accuracy looks quite the same.\n",
        "\n",
        "  - Validation set - comparing to previous pseudo labeling method, loss is slightly lower and accuracy is a bit lower.\n",
        "\n",
        "**Conclusions and next steps**\n",
        "- Pseudo labeling technique did show only slight improvements in loss and accuracy.\n",
        "\n",
        "- Improvements might be more noticable if comparison will be based on training accuracy and not epochs number ( as mentioned above in comparision )\n",
        "- It is worth checking different rations of labeled/pseusdo labeled imgs in a batch.\n",
        "\n",
        "- Current pseudo labeling generator does not implement batch shuffeling!\n",
        "Implementing shuffle might increase performance aswell.\n"
      ]
    }
  ]
}